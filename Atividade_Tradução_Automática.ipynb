{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, SimpleRNN\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "D3ha3iP7Wgbn"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVyRtOIVWKP2",
        "outputId": "992da7ba-65f7-4547-f336-a0c3e621917e"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnhSfLNuUXdq",
        "outputId": "bcbe1de7-3f82-4aa4-c574-0ca049b698e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         146680                Uma menina chorando abriu a porta.     267881  \\\n",
            "18018   1047028            Quando você começou a aprender alemão?   427847.0   \n",
            "195378  7297179                        Detestei estudar esloveno.  7985459.0   \n",
            "55594   2695021                            A minha opinião mudou.  2693752.0   \n",
            "201779  8165254           Tom e Mary são membros da mesma igreja.  8093131.0   \n",
            "53895   2623428  Exercícios regulares são benéficos para a saúde.    20214.0   \n",
            "\n",
            "                        A crying girl opened the door.  \n",
            "18018              When did you start learning German?  \n",
            "195378                     I hated studying Slovenian.  \n",
            "55594                          My opinion has changed.  \n",
            "201779    Tom and Mary are members of the same church.  \n",
            "53895   Regular exercise is beneficial to good health.  \n",
            "(292877, 4)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Inteli/Módulo 11 - Brastel/Ponderada Hayashi Tradução/Sentence pairs in Portuguese-English - 2024-09-09.tsv', delimiter='\\t')\n",
        "df = df.sample(frac = 1)\n",
        "print(df.head())\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leave only the columns with sentences\n",
        "df = pd.DataFrame(df.iloc[:, [1, 3]].values, columns=['Original (PT)', 'Tradução (EN)'])\n",
        "\n",
        "# Ensure all values in 'Tradução (EN)' are strings\n",
        "df['Tradução (EN)'] = df['Tradução (EN)'].astype(str)\n",
        "\n",
        "# Calculate the number of words in each sentence for both columns\n",
        "df['PT_word_count'] = df['Original (PT)'].str.split().str.len()\n",
        "df['EN_word_count'] = df['Tradução (EN)'].str.split().str.len()\n",
        "\n",
        "# Filter out sentences with more than 10 words in either language\n",
        "df = df[(df['PT_word_count'] <= 10) & (df['EN_word_count'] <= 10)]\n",
        "\n",
        "# Drop the temporary word count columns\n",
        "df = df.drop(['PT_word_count', 'EN_word_count'], axis=1)"
      ],
      "metadata": {
        "id": "9LBBRVE5JzcO"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_pt = Tokenizer()\n",
        "tokenizer_en = Tokenizer()\n",
        "\n",
        "tokenizer_pt.fit_on_texts(df['Original (PT)'])\n",
        "tokenizer_en.fit_on_texts(df['Tradução (EN)'])\n",
        "\n",
        "# Get the sequences padded\n",
        "sequences_pt = tokenizer_pt.texts_to_sequences(df['Original (PT)'])\n",
        "sequences_en = tokenizer_en.texts_to_sequences(df['Tradução (EN)'])\n",
        "\n",
        "padded_sequences_pt = pad_sequences(sequences_pt, padding='post')\n",
        "padded_sequences_en = pad_sequences(sequences_en, padding='post')"
      ],
      "metadata": {
        "id": "huOD-cbYWL_4"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(padded_sequences_pt[0])\n",
        "print(padded_sequences_en[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kh7ZoP2SIEn",
        "outputId": "0fbfe980-095f-4798-966d-344a0a5c96af"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 70   9 285   7 238 611   0   0   0   0   0   0]\n",
            "[ 82  36   5 425 483 580   0   0   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first sentence of padded_sequences_pt and padded_senquences_en, revert the indexing to get the original sentence\n",
        "print(tokenizer_pt.sequences_to_texts([padded_sequences_pt[0]])[0])\n",
        "print(tokenizer_en.sequences_to_texts([padded_sequences_en[0]])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0yz_c97XmXr",
        "outputId": "47e8d5da-9641-4d6e-c02d-c41545ca8de2"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quando você começou a aprender alemão\n",
            "when did you start learning german\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_pt = MinMaxScaler()\n",
        "scaler_en = MinMaxScaler()\n",
        "padded_sequences_pt = scaler_pt.fit_transform(padded_sequences_pt)\n",
        "padded_sequences_en = scaler_en.fit_transform(padded_sequences_en)"
      ],
      "metadata": {
        "id": "d-T1vJsIX_AX"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(padded_sequences_pt.shape)\n",
        "print(padded_sequences_en.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLXvK-seM8xc",
        "outputId": "da553b57-6ba8-4888-b3ff-3406edf61210"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(254711, 12)\n",
            "(254711, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = padded_sequences_pt[:int(0.8 * len(padded_sequences_pt))]\n",
        "test_data = padded_sequences_pt[int(0.8 * len(padded_sequences_pt)):]\n",
        "train_labels = padded_sequences_en[:int(0.8 * len(padded_sequences_en))]\n",
        "test_labels = padded_sequences_en[int(0.8 * len(padded_sequences_en)):]"
      ],
      "metadata": {
        "id": "LKJp9GAHNiRy"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNNmodel = Sequential([\n",
        "    Input(shape=(padded_sequences_pt.shape[1],1), batch_size=2),\n",
        "    SimpleRNN(units=(16)),\n",
        "    Dense(padded_sequences_en.shape[1])\n",
        "])\n",
        "\n",
        "RNNmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "loss = RNNmodel.fit(train_data, train_labels, epochs=1)\n",
        "loss = loss.history['loss']\n",
        "\n",
        "predicted_sentences = RNNmodel.predict(test_data)"
      ],
      "metadata": {
        "id": "QTdHvxLB_Ilx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b371bdd3-c7cf-43b9-d327-a292d7915b03"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6368/6368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - loss: 0.0028\n",
            "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the predicted sentences back to actual sentences\n",
        "predicted_sentences = scaler_en.inverse_transform(predicted_sentences)\n",
        "predicted_sentences = predicted_sentences.astype(int)\n",
        "predicted_sentences = tokenizer_en.sequences_to_texts(predicted_sentences)\n",
        "\n",
        "test_labels = scaler_en.inverse_transform(test_labels)\n",
        "test_labels = test_labels.astype(int)\n",
        "test_labels = tokenizer_en.sequences_to_texts(test_labels)"
      ],
      "metadata": {
        "id": "nB1EQsw9RyEn"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels[0])\n",
        "print(predicted_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "954HB9i_Zjuq",
        "outputId": "eacb3bee-19a2-4f42-9493-c8f6602416c0"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i promise you i won't stay out too late\n",
            "once use went wouldn't big because talk come an like i\n"
          ]
        }
      ]
    }
  ]
}